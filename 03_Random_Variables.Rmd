
# Random Variables and Distributions

## Defining Random Variables and Discrete Distributions

A random variable is a _function_ that takes outcomes in the sample space $\mathcal{S}$ and maps them to numeric values in $\mathbb{R}$. Often times we abbreviate random variable as RV.

The idea is that random events such as flipping Heads, a medical test showing the patient has a disease, Chris Froome winning the Tour de France, or rolling a Leaning Jowler in _Pass the Pigs_ are all random events but to do math on them, we need to turn them into numbers.

In cases where the sample space $\mathcal{S}$ is already numeric, the random variable can just be the identity, but in other cases, we might have to be more careful.  For example, if my experiment is flipping a fair coin $n=4$ times, I could define the random variable $X=$ number of heads and $X$ could take on any of the values $x \in \{0,1,2,3,4\}$.  I could similarly define 

$$Y= \begin{cases} 
  0 \;\;\; \textrm{ if number of heads } < 2 \\ 
  1 \;\;\; \textrm{ if number of heads } > 2 
\end{cases}$$ 
                   
A RV function doesn't have to be one-to-one and it doesn't have to map to the entire set of real values.

Because events in the sample space $\mathcal{S}$ have an associated probability, then it is natural to define an event, say $B$ to be all the outcomes $s \in \mathcal{S}$ such that $X(s) = x$ and then define $Pr(X=x) = Pr(B)$.

Notation: We will refer to the random variable using the capital letters, (e.g. $X$, $Y$, $Z$, $W$) and the possible values they take on using lower case letters. With this notation, the RV $X$ could take on values $x \in \{0,1,2,3,4\}$

1. We consider flipping a fair coin $n=4$ times.
    a) What is the set of outcomes?  As usual, we will define an event for each outcome.
    b) What is the probability of each outcome?
    c) For the RV $X$ defined above, what outcomes define the event $B$ such that $s \in B \implies X(s)=2$?
    d) What is $Pr(B)$? Therefore what is $Pr(X=2)$?
    e) For the RV $Y$ defined above, what outcomes define the event $A$ such that $s \in A \implies Y(s)=1$?
    f) What is $Pr(A)$? Therefore what is $Pr(Y=1)$?
    
For each value that $X$ or $Y$ could take on, we could figure out the probability of the associated event.  We define the random variables _distribution_ as a description of what values the RV can take on and $Pr(X \in C)$, for any interval $C = \{c: a\le c \le b\}$ for any $a<b$.  This is actually a very awkward definition and we will examine more convenient ways to specify these same probabilities.

**Discrete** random variables are RVs that can only take on a finite or countably infinite set of values.

**Continuous** random variables are RVs that can take on an unaccountably infinite set of values.

We now define the _probability function_ of a discrete RV $X$ as 
$$f(x) = Pr(X = x)$$
and the closure of the set $\{x: \textrm{ such that } f(x) > 0\}$ is referred to as the _support of $X$_. Notice that this function is defined for all $x\in \mathbb{R}$, but for only a countable number of cases is $f(x)>0$.

2. Suppose that RV $X$ can take on the values $\{x_1,x_2,\dots,x_K\}$. Prove that $$\sum_{k=1}^K f(x_k) = 1$$

3. **Bernoulli Distribution**.  Suppose that the random variable $W$ takes on the values $0$ and $1$ with the probabilities $Pr(W=1) = p$ and $Pr(W=0) = 1-p$.  Then we say that $W$ has a Bernoulli distribution with probability of success $p$, which I might write as $W \sim Bernoulli(p)$. Show that for any interval $C =\{c: a\le c \le b\}$ in $\mathbb{R}$, you can find $Pr(W \in C)$.

4. **Uniform Distribution on Integers**. Suppose that we have integers $a$ and $b$ such that $a < b$.  Suppose that the RV $X$ is equally likely to be any of the consecutive integers $a,\dots,b$. What is $f(x)$? _(Make sure your definition applies to any $x\in\mathbb{R}$)_

5. **Binomial Distribution** Suppose that we have an experiment that consists of $n$ independent Bernoulli($p$) trials. We are interested in the distribution of $X=$ # of successful trials. That is $X\sim Binomial(n,p)$.
    a) For any integer $x \in \{0,1,\dots,n\}$, what is $Pr(X=x)$?
    b) Define $f(x)$ for all values of $x \in \mathbb{R}$.

6. Give two examples of random variables which have Bernoulli($p=1/2$) distributions.  These two RVs should not the same RVs, but they have the same distribution.  That is to say, RVs have distributions, but distributions are not RVs.

7. Suppose that two fair six-sided dice are rolled and the RV of interest is the absolute value of the difference between the dice. Give the probability distribution along with an illuminating graph.

8. Suppose that a box contains 7 red balls and 3 green balls. If five balls are selected at random, without replacement, determine the probability function of $X$ where $X$ is the number of red balls selected.

9. Suppose that a random variable $X$ has a discrete distribution with the following probability function:
$$f(x) = \begin{cases} 
  \frac{c}{2^x} \;\textrm{ for } x = 0, 1, 2, \dots \\
  0 \;\;\;\; \textrm{otherwise}
\end{cases}$$
Find the value for $c$ that forces the requirement that $$\sum_{x=0}^\infty f(x) = 1$$ _Hint: This is a particular power series. Go to any Calculus book (or internet) for an appropriate result. Make sure you introduce the result and show why the result applies to $f(x)$ in your solution._

For the binomial distribution (and many distributions we will consider this semester), it would be nice to not have to calculate various probabilities by hand. Most mathematical software packages include some way to calculate these probabilities.  

|  System     |     Documentation Link or site link                                                |
|:-----------:|:-----------------------------------------------------------------------------------|
| Matlab      |  https://www.mathworks.com/help/stats/working-with-probability-distributions.html  |
| Mathematica |  http://reference.wolfram.com/language/howto/WorkWithStatisticalDistributions.html |
| R           |  https://dereksonderegger.github.io/570L/3-statistical-tables.html                 |
| Web App     |  https://ismay.shinyapps.io/ProbApp/                                               |

10. Each time I ride home or to work, there is a $p=0.1$ probability that I will get stopped by a train.  Let $X$ be the number of times I'm stopped by the train in the next 10 trips. Assume that the probability I'm stopped on trip $i$ is independent of all other trips $j$.
    a) What is the distribution of $X$? Remember, to specify the distribution by name, you must specify the name and the value of all parameters.
    b) What is $Pr(X =6)$?
    c) What is $Pr(X < 6)$?
    d) What is $Pr(X \ge 6)$?


## Continuous Distributions

We wish to define something similar to the probability function for continuous RVs. However, because there are an uncountable number of values that the RV could take on, we have to be careful and define probability on intervals of the form $[a,b]$. We define the _probability density function_ (usually denoted pdf) as the function $f(x)$ such that 
$$Pr( a \le X \le b) = \int_a^b f(x) dx$$

We further define the support of the distribution as the closure of the set ${x: f(x)>0}$. This is the second time we've defined the support as the _closure_ of the set.  In the discrete case, it didn't really matter, but here it does. If we define the pdf on the set $[0,1]$ versus $(0,1)$, we want the support to contain the end points of the interval, that is the support is the closure of $(0,1)$ which is $[0,1]$.

1. Show that, for any $a\in\mathbb{R}$, $Pr( X = a ) = 0$ is consistent with this definition of $f(x)$.  _Hint: What happens as $b-a$ gets small?  Take the limit._

2. Prove that $\int_{-\infty}^\infty f(x) dx = 1$.

Further notice that $f(x)\ge0$ for all $x$ because otherwise that would imply that there are events with negative probabilities.

3. **Continuous Uniform**.  Suppose that the random variable $X$ will be a randomly chosen real value from the interval $[a,b]$. Suppose that for any sub interval $d=[d_1,d_2]$ where $a \le d_1 \le d_2 \le b$, that $Pr( X \in d)$ is proportional to the length of the interval $d$.  What is the pdf of the distribution of $X$?

It is unfortunate that your book doesn't introduce indicator functions at this point in time. We can define the following:
$$I( \textrm{logical test} ) = 
    \begin{cases} 1 \;\;\; \textrm{ if logical test is true } \\
                  0 \;\;\; \textrm{ if logical test is false } \end{cases}$$

4. Suppose that the pdf of a random variable $X$ is $$f(x) = \frac{4}{3}\left(1-x^3\right) \;I(0<x<1)$$
    a) Create a graph of the pdf.
    b) Find $Pr\left( X\le \frac{1}{2} \right)$?
    c) Find $Pr\left( \frac{1}{4} < X < \frac{3}{4} \right)$
    d) Find $Pr\left( X > \frac{3}{4} \right)$

5. Suppose the random variable $X$ has pdf 
$$f(x) = c\cdot e^{-5x}I(x\ge 0) = \begin{cases} c\cdot e^{-5 x} \;\;\; \textrm{ if } x \ge 0 \\
                                          0   \;\;\;\;\;\;\;\;\;\;\;\;\; \textrm{otherwise}
                            \end{cases}$$
    a) What is the value of $c$ that makes this a valid pdf?  That is, what value of $c$ makes this function integrate to 1?
    b) Graph this function. What is $f(0)$? Many students dislike that $f(0)>1$ is greater than one. Why isn't this a problem?
    c) What is the probability $Pr(X \le 0.5)$?
    
6. Suppose that the pdf of the random variable $X$ is
$$f(x)= c \cdot x \;\;I(0\le x \le 3)$$
    a) What value of $c$ makes this a valid pdf?
    b) Find a value of $t$ such that $Pr( X \le t ) = 0.25)$
    c) Find a value of $t$ such that $Pr( X > t) = 0.5)$

7. Given the same random variable $X$ described in problem 3.2.5, consider the random variable $Y$ which is the simply the nearest integer to $X$. What is the pf of $Y$?



We now have defined both the probability function (pf) for discrete random variables and probability density function (pdf) for continuous random variables.  We now try to make a physics analogy to describe the difference between the two. In both cases we want to think about probability as physical mass.  

**Discrete Case** In this case, all the probability mass is concentrated at precise points.  So we have little nuggets of probability mass, at discrete points.  If I want to know, say $Pr(X \le 3)$ then we have to sum the probability across all the discrete locations such that $X \le 3$.

**Continuous Case** In this case, the probability mass is spread out across $\mathbb{R}$ and the concentration of mass is not uniform, some spots have more concentrated mass.  In this case, we don't have a definite amount of mass at a particular point, but we do have a description of how dense the mass is at any point.  In this case if we want to know $Pr(X \le 3)$ then we have to break up $\mathbb{R}$ into a bunch of intervals and then combine the length of the interval along with information about the average density of each interval.

```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3}
library(ggplot2); library(dplyr);
curve.data <- data.frame( x = seq(-3, 7, by=0.01) ) %>%
  mutate( density = dnorm(x, mean=2, sd=1))
hist.data <- data.frame( x = seq(-3.25, 2.75, by=0.5) ) %>%
  mutate(density = dnorm(x, mean=2, sd=1))

ggplot(curve.data, aes(x=x, y=density)) + 
  geom_line() +
  geom_bar(data=hist.data, stat='identity', width=.5, alpha=.3, color='red') +
  scale_x_continuous(breaks=-3:7, minor=NULL)  
```
    
Each bar has some probability mass (mass is the length of the interval times the average density along the interval) and then we just sum up the bars.  If we take the limit as we make the bars narrower, then we end up with 
$$Pr(X \le 3) = \int_{-\infty}^3 f(x) \, dx$$

You might be a little freaked out because typically you would think about mass being the _area_ or _volume_ times the density, but we need to start in the 1-dimension case before we address the 2-dimension and 3-dimension cases.


## Cumulative Distribution Function

It is somewhat annoying to mathematically describe distributions in two different ways, depending on if the random variable is discrete or continuous.

$$\begin{aligned}
  Pr \left( X=x \right) = f(x) \;\;\; & \textrm{ if X is discrete RV } \\
  Pr \left(a \le X \le b\right) = \int_a^b f(x)\,dx \;\;\; & \textrm{ if X is continuous RV } 
  \end{aligned}$$
  
While the probability function and probability density function are both useful functions, it is mathematically convenient to have a mathematical description of the distribution that has the same interpretation regardless of if the distribution is discrete or continuous.  

_Definition_: For a random variable $X$ (notice we don't specify if it is continuous or discrete) the **Cumulative Distribution Function** (CDF) is defined as 
$$F(x) = Pr( X \le x )$$
Notice that this is defined for all $x$ in $\mathbb{R}$.

1. Suppose that random variable $X$ has a Uniform distribution on the integers $1,2,3,4,5$. These are the only values that $X$ can take on, and $$f(x) = \frac{1}{5} \, \cdot I\Big(x \in \{1,2,\dots,5\}\Big)$$ Draw a graph of $F(x)$ and make sure the graph demonstrates:
    a) That $F(x)$ is defined for all $x \in \mathbb{R}$.
    b) That $F(x)$ is a step function.
    c) That $F(x)$ is continuous from the right. *That is, for $\epsilon > 0$,  $\lim_{\epsilon \to 0} F(x+\epsilon) = F(x)$.*
    d) That $\lim_{x\to -\infty} F(x) = 0$.
    e) That $\lim_{x\to \infty} F(x) = 1$.
    
Define $B_x = \left\{s \textrm{ such that } X(s) \le x\right\}$. Then we have for $x_1 < x_2$ that $B_{x_1} \subset B_{x_2}$ and therefore:
$$\lim_{x\to -\infty} F(x) = \lim_{x\to -\infty} Pr\left( B_{x} \right) = Pr( \emptyset ) = 0$$ 
$$\lim_{x\to  \infty} F(x) = \lim_{x\to  \infty} Pr\left( B_{x} \right) = Pr( \mathcal{S} ) = 1$$ 

2. Show that $F(x)$ must be non-decreasing.  *Notice this allows for $F(x)$ to be a flat function, but cannot decrease.*

3. Suppose that the r.v. $X$ has a Binomial($n=5$, $p=0.8$) distribution. Sketch the CDF.

4. **Geometric Distribution** Suppose that we flip a biased coin that has probability of heads as $p \in [0,1]$. Let the r.v. $X$ be the number of coin flips until the first head is observed.
    a) What values could $X$ take? Mathematically, we say, what is the support of $X$?
    b) Is $X$ a continuous or discrete random variable?
    c) Find the probability function, $f(x)$.
    d) Show that cummulative distribution function is $F(x) = 1 - (1-p)^x$. *Hint: Geometric Series!*
    

For continuous random variables it is relatively easy to go back and forth from the cdf to the pdf (assuming the integration and differentiation isn't too hard).
$$ F(x) = \int_\infty ^x f(u) \, du$$
$$ f(x) = \frac{d}{dx}\, F(x)$$


5. **Exponential Distribution** (Warning! There are two ways to parameterize the Exponential Distribution. Before you look anything up, make sure it is using the same parameterization you are.) Suppose that we have a continuous random variable $X$ with pdf
$$f(x) = \beta e ^{-\beta x} \;\cdot I(x > 0)$$
    a) Find the cdf function $F(x)$.
    b) For $\beta=2$ sketch the pdf and cdf.
    c) On the pdf and cdf graphs, represent $Pr(X < 1)$.  *In the pdf it will be some shaded area, in the cdf it is something else.*
    

6. Suppose that the cdf of a random variable $X$ is as follows:
$$ F(x) = \begin{cases} 
  0 \;\;\;          & \textrm{ for } x \le 0 \\
  \frac{1}{9} x^2   & \textrm{ for } 0 \le x \le 3 \\
  1                 & \textrm{ for } x > 3 
  \end{cases}$$
    a) Find the pdf function $f(x)$.
    b) Sketch the pdf and cdf.
    c) On the pdf and cdf graphs, represent $Pr( X \le 2 )$.
    
7. Suppose that a point in the $xy$-plane is chosen at random from the interior of the unit circle, which is the circle centered at $(0,0)$ with radius 1. Notice the probability that the chosen point belongs to a given region is proportional to the area of the region. Let the random variable $Z$ represent the distance of the point to the origin.
    a) Find and sketch the cdf of $Z$.
    b) Find and sketch the pdf of $Z$.
    c) On the pdf and cdf graphs, represent $Pr( Z \le 0.5 )$.
    

We think of the cdf as a function that takes some value $x$ and produces a probability. In the case where $F(x)$ is monotonically increasing, we could define $F^{-1}(p)$ which takes a probability and tells us what value of $x$ produces $F(x)=p$.

The _quantile function_ of a distribution generalizes the inverse function to work similarly for non-decreasing functions by defining
$$F^{-1}(p) = \min(x) \textrm{ such that } F(x) \ge p$$


8. Suppose that a point in the $xy$-plane is chosen at random from the interior of the unit circle, which is the circle centered at $\{0,0\}$ with radius 1. Notice the probability that the chosen point belongs to a given region is proportional to the area of the region. Let the random variable $Z$ represent the distance of the point to the origin.
    a) What is the median of the distribution? That is, find the value $z$ such that $Pr(Z \le z)=0.5$.
    b) Again sketch the pdf and cdf of this distribution and reperesent the median on both graphs along with pertinent information showing that indeed the value you found is the median.
    c) What is the $75$th percentile? Follow your previous steps in part (a) and (b).
    
9. **Binomial Distribution** Again we consider the binomial distribution but now with parameters $n=6$ and probability of success $p=0.4$. 
    a) Find and graph the pdf and cdf of this distribution.
    b) What is the median of this distribution?
    c) What is the $75$th percentile? What is the $80$th percentile?
    
## Bivariate Distributions
We now consider the case of having two random variables.  We can think of selecting an individual from a population and measuring two (or more!) variables.  For example, we might select a NAU student and measure both their height and weight and we want to understand how those two measurements vary. It should be clear that there is a positive correlation (taller people also tend to weigh more) and we want to estabilish the mathematical framework to address questions such as this.

In general we will consider the distribution of 2 or more random variables and we will call this the _joint distribution_. In the bivariate case, we will consider the joint distribution of $X$ and $Y$.

### Bivariate Discrete
We first consider the case where both variables are discrete. In this case, the bivariate distribution can be defined by simply defining the probabilities $f(x,y)=Pr(X=x, Y=y)$.  Your book likes to emphasize the notation of an $(X,Y)$ pair and writes these as $Pr\Big( (X,Y) = (x,y)\Big)$, but I dislike so many parentheses.

1. Consider the experiment of rolling two six-sided fair dice. Define the discrete random variable $X$ as the number of ones we roll and $Y$ as the number of sixes.  
    a) Fill in the table of $f(x,y)$ values.
        
        |  $f(x,y)$   |   $Y=0$     | $Y=1$         |  $Y=2$      |
        |:-----------:|:-----------:|:-------------:|:-----------:|
        | $X=0$       |             |               |             |
        | $X=1$       |             |               |             |
        | $X=2$       |             |               |             |
    
    b) Find $Pr( X\ge 1 \textrm{ and } Y \ge 1 )$


2. Suppose that $X$ and $Y$ have a discrete joint distribution for which the joint p.f. is defined as follows:
$$f(x,y) = \begin{cases}
  c|x+y| & \textrm{ for } x \in \{−2,−1,0,1,2\} \\
         & \textrm{ and } y \in \{−2,−1,0,1,2\} \\
  0      & \textrm{ otherwise. }
  \end{cases}$$
    a) Find the value of the constant $c$.
    b) Find $Pr(X = 0 \textrm{ and } Y =−2)$.
    c) Find $Pr(X=1)$
    d) Find $Pr(|X−Y|≤1)$
    

### Bivariate Continuous
Two random variables $X$ and $Y$ have a bivariate continuous distribution  if there exists a non-negative function $f(x,y)$ such that for every subset $C$ of the $xy$-plane 
$$Pr\Big[ (X,Y)\in C\Big] = \iint_C f(x,y)$$

Unsurprisingly, the requirements for a function $f(x,y)$ to be a joint pdf are:
 $$f(x,y) \ge 0 \textrm{ for all } (x,y) \textrm{ in } \mathbb{R}^2$$
 $$\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x,y) \, dx\,dy = 1$$
 
3. Suppose the random variables $X$ and $Y$ have joint pdf 
$$f(x,y) = c x^2 y \,\cdot I(x^2 \le y \le 1)$$
    a) Draw the support of this distribution by drawing the parabola $y=x^2$ on the $xy$-plane and shade in the area for which $f(x,y)>0$. Denote this region as $D$
    b) Integrate $f(x,y)$ over its support.  That is, find $\iint_D f(x,y) \, dx\,dy$.
    c) What is the value of $c$ so that $\iint f(x,y) \, dx\,dy = 1$?
    d) Find $Pr( X>0 \textrm{ and } Y>X )$ by shading in the area of the $xy$-plane corresponding to this event and then integrating $f(x,y)$ over this region. 