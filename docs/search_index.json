[
["A-gamma-function.html", "A Gamma Function", " A Gamma Function We want to generalize the factorial function which was \\[n! = n(n-1)(n-2)\\dots(2)(1)\\] for \\(n \\in \\{0, 1, 2, \\dots\\}\\) and we define \\(0!=1\\) for notational convenience because that is what we need in many formulas. Notice that \\(1! = 1\\), \\(2!=2\\) and \\(3! = 3 * 2!\\). The problem is that this is only defined for the whole numbers (natural numbers and zero). We want to define a function that allows us to expand this function to the positive real numbers. Consider the funtion: \\[\\Gamma(x) = \\int_0^\\infty z^{x-1} e^{-z} \\,dz\\] First we show that \\(\\Gamma(x) = (x-1)\\Gamma(x-1)\\) utilizing integration by parts. \\[\\begin{aligned} u = z^{x-1} &amp;\\;\\;\\; &amp; dv = e^{-z}\\,dz \\\\ du = (x-1)z^{x-2}\\,dx &amp;\\;\\;\\; &amp; v = -e^{-z} \\end{aligned}\\] and therefore \\[\\begin{aligned} \\Gamma(x) &amp;= \\int_0^\\infty z^{x-1} e^{-z} \\,dz \\\\ &amp;= \\int_0^\\infty u \\;dv \\\\ &amp;= uv\\vert_0^\\infty - \\int_0^\\infty v\\, du \\\\ &amp;= -z^{x-1}e^{-z}\\vert_{z=0}^\\infty + \\int_0^\\infty (x-1)z^{x-2}e^{-z} \\, dz\\\\ &amp;= (x-1) \\int_0^\\infty z^{x-2}e^{-z}\\,dz\\\\ &amp;= (x-1) \\Gamma(x-1) \\end{aligned}\\] Next we notice that \\(\\Gamma(1) = 1 = 0!\\) via the following integration \\[\\Gamma(1) = \\int_0^\\infty z^{1-1}e^{-z}\\,dz = \\int_0^\\infty e^{-z} \\,dz = -e^{-z} \\vert_0^\\infty = 1\\] Using these bits, we can see that \\[\\Gamma(2) = 1\\cdot \\Gamma(1) = 1 = 1!\\] \\[\\Gamma(3) = 2 \\Gamma(2) = 2 = 2!\\] \\[\\Gamma(4) = 3 \\Gamma(3) = 3 \\cdot 2! = 3!\\] and for positive integers \\(n\\), \\[\\Gamma(n) = (n-1)!\\] which can be re-arranged to see that \\[n! = n \\Gamma(n)\\] We conclude by noting that \\[\\Gamma\\left( \\frac{1}{2} \\right) = \\sqrt \\pi\\] (This result can be obtained by looking at the square of the integral and then doing a trig substitution.) A graph of this on the postive real numbers is given below: Finally we note that there is a reasonable approximation (known as Stirling’s approximation) to the function for large values of \\(x\\) as \\[\\Gamma(x+1) \\approx \\sqrt{ 2 \\pi x } \\left( \\frac{x}{e} \\right)^x\\] "],
["B-useful-series-results.html", "B Useful Series Results B.1 \\(e^x\\)", " B Useful Series Results B.1 \\(e^x\\) In many calculus books, the following is shown (for any \\(x\\)): \\[e^x = \\sum_{i=0}^\\infty \\frac{x^i}{i!}\\] Another series result for \\(e^x\\) is \\[e^x = \\lim_{n \\to \\infty} \\left( 1 + \\frac{x_n}{n} \\right)^n \\;\\;\\;\\;\\; \\textrm{ if } \\;\\; x_n \\to x\\] ## Geometric Series The geometric series result is that \\[\\sum_{x=0}^\\infty \\alpha^x = \\frac{1}{1-\\alpha}\\;\\;\\;\\; \\textrm{ if } \\;\\;\\;\\vert\\alpha\\vert&lt;1\\] By repeatedly differentiating both sides we can derive \\[\\sum_{x=1}^\\infty x \\alpha ^{x-1} = \\frac{1}{ (1-\\alpha)^2 }\\;\\;\\;\\; \\textrm{ if } \\;\\;\\;\\vert\\alpha\\vert&lt;1\\] and \\[\\sum_{x=2}^\\infty x(x-1) \\alpha^{x-2} = \\frac{2}{(1-\\alpha)^3}\\;\\;\\;\\; \\textrm{ if } \\;\\;\\;\\vert\\alpha\\vert&lt;1\\] "],
["C-tedious-results.html", "C Tedious results C.1 Normal distribution", " C Tedious results C.1 Normal distribution The normal distribution with parameters \\(\\mu\\) and \\(\\sigma^2 &gt; 0\\) has pdf \\[f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left[ -\\frac{(x-\\mu)^2}{2 \\sigma^2} \\right]\\] It is clear \\(f(x)&gt;0\\) for all \\(x\\), but we should confirm that this pdf integrates to one. Unfortunately this integral is one of those that either you know how to solve or you waste a huge amount of time with. First, we will perform a substitution of \\(z=\\frac{x-\\mu}{\\sigma}\\) and therefore \\(dz = dx/\\sigma\\) and we are interested in showing that \\[\\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} \\, dz = 1\\] or equivalently that \\[\\underbrace{\\int_{-\\infty}^{\\infty} e^{-z^2/2} \\, dz}_{I} = \\sqrt{2\\pi}\\] or that \\[I^2 = 2\\pi\\] We will consider this \\(I^2\\) value as \\[\\begin{aligned} I^2 &amp;= \\int_{-\\infty}^{\\infty} e^{-z^2/2} \\, dz \\; \\int_{-\\infty}^{\\infty} e^{-w^2/2} \\, dw \\\\ &amp;= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-z^2/2} \\,e^{-w^2/2} \\, dz\\,dw \\\\ &amp;= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2}(z^2 + w^2)} \\, dz\\,dw \\\\ \\end{aligned}\\] Because \\(z^2 + w^2\\) is the equation of a circle in the \\(z,w\\) plane, we think to convert to polar coordinates with the subsitution \\(z=r \\cos \\theta\\) and \\(w= r \\sin \\theta\\) and therefore \\(z^2 + w^2 = r^2\\) and \\(dz\\,dw = r\\, dr\\, d\\theta\\) therefore \\[\\begin{aligned} I^2 &amp;= \\int_0^{2\\pi} \\int_0^{\\infty} e^{-\\frac{1}{2} r^2} \\,r \\, dr \\, d\\theta \\end{aligned}\\] Finally this integral can be attacked using common methods and we’ll do a \\(u\\)-substitution with \\(u=r^2/2\\) and therefore \\(du=r\\,dr\\) and we have \\[\\begin{aligned} I^2 &amp;= \\int_0^{2\\pi} \\int_0^{\\infty} e^{-u} \\, du \\, d\\theta \\\\ &amp;= \\int_0^{2\\pi} 1 \\, d\\theta \\\\ &amp;= 2 \\pi \\end{aligned}\\] "],
["D-distributions.html", "D Distributions D.1 Discrete Distributions", " D Distributions D.1 Discrete Distributions Bernoulli(p) Binomial(n, p) p.f. \\(f(x)=p^x(1-p)^{1-x}\\) for \\(x=0,1\\) \\(f(x) = {n \\choose x} p^x (1-p)^{n-x}\\) for \\(x=0,1,\\dots,n\\) Mean \\(p\\) \\(np\\) Variance \\(p(1-p)\\) \\(np(1-p)\\) CDF \\(F(x) = e^x\\) m.g.f. \\(\\psi(t)=pe^t+1-p\\) \\(\\psi(t)=( pe^t + 1-p )^n\\) ‘\\[F(x) = \\cases{ \\begin{aligned} 0 &amp;\\;\\;\\;\\;\\; x &lt; 0\\\\ (1-p) &amp;\\;\\;\\;\\;\\; 0 \\le x &lt; 1\\\\ 1 &amp;\\;\\;\\;\\;\\; 1 \\le x \\end{aligned}}\\]’ Bernoulli &lt;- data.frame( name=&#39;Bernoulli(p)&#39;, pf = &#39;$f(x) = p^x (1-p)^{1-x}$&#39;, Mean=&#39;$p$&#39;, Variance = &#39;$p(1-p)$&#39;, CDF = &#39;$$F(x) = \\\\cases{ \\\\begin{aligned} 0 &amp; \\\\;\\\\;\\\\;\\\\;\\\\; x &lt; 0 \\\\\\\\ (1-p) &amp; \\\\;\\\\;\\\\;\\\\;\\\\; 0 \\\\le x &lt; 1 \\\\\\\\ 1 &amp; \\\\;\\\\;\\\\;\\\\;\\\\; 1 \\\\le x \\\\end{aligned}}$$&#39;, mgf = &#39;$\\\\psi(t) = pe^t + 1-p$&#39; ) Binomial &lt;- data.frame( name=&#39;Binomial(n,p)&#39;, pf = &#39;$f(x) = { n \\\\choose x } p^x (1-p)^{n-x}$&#39;, Mean = &#39;$np$&#39;, Variance = &#39;$np(1-p)$&#39;, CDF = &#39;Too many cases to be shown here&#39;, mgf = &#39;$\\\\psi(t) = ( pe^t - 1-p )^n$&#39; ) out &lt;- t( rbind(Bernoulli, Binomial) ) colnames(out) &lt;- NULL pander::pander(out) name Bernoulli(p) Binomial(n,p) pf \\(f(x) = p^x (1-p)^{1-x}\\) \\(f(x) = { n \\choose x } p^x (1-p)^{n-x}\\) Mean \\(p\\) \\(np\\) Variance \\(p(1-p)\\) \\(np(1-p)\\) CDF \\[F(x) = \\cases{ \\begin{aligned} 0 &amp; \\;\\;\\;\\;\\; x &lt; 0 \\\\ (1-p) &amp; \\;\\;\\;\\;\\; 0 \\le x &lt; 1 \\\\ 1 &amp; \\;\\;\\;\\;\\; 1 \\le x \\end{aligned}}\\] Too many cases to be shown here mgf \\(\\psi(t) = pe^t + 1-p\\) \\(\\psi(t) = ( pe^t - 1-p )^n\\) "]
]
